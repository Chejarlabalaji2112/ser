{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227301f3",
   "metadata": {},
   "source": [
    "# Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a6b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for building and evaluating a neural network\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "\n",
    "# Layers from Keras (for defining the model architecture)\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, Activation\n",
    "\n",
    "# Sequential model class from Keras (to build the model layer by layer)\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Evaluation tools from Scikit-learn (to assess model performance)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Data splitting tool from Scikit-learn (to split the data into training and testing sets)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61eeafc",
   "metadata": {},
   "source": [
    "___\n",
    "Testing Audio Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe0b3b6",
   "metadata": {},
   "source": [
    "from IPython.display import Audio, display\n",
    "a_path = '/home/badri/B/ser/datasets/revdess/Actor_01/03-01-01-01-01-01-01.wav'\n",
    "a_path = '/home/badri/B/ser/datasets/neutral.wav'\n",
    "sr = 22050\n",
    "display(Audio(filename=a_path, rate = sr))\n",
    "a_path = '/home/badri/B/ser/datasets/sad_audio.wav'\n",
    "\n",
    "y,sam_r = librosa.load(a_path, sr = sr)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "librosa.display.waveshow(y, sr = sr)\n",
    "plt.title(\"testing_wave_form\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9cd329",
   "metadata": {},
   "source": [
    "end\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5539fe9a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Feature Extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e660b6",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def extract_mfcc(file_path, sr = 22050, n_mfcc = 40):\n",
    "    y,sr = librosa.load(file_path, sr=sr, res_type='kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs_mean\n",
    "\n",
    "dataset_path = '/home/badri/B/ser/datasets/revdess/'\n",
    "\n",
    "mfcc_features = []\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            try:\n",
    "                file_path = os.path.join(root, file)\n",
    "                mfccs = extract_mfcc(file_path)\n",
    "                file_class = int(file[7:8]) -1 \n",
    "                mfcc_features.append((mfccs, file_class))\n",
    "            except ValueError as err:\n",
    "                print(f\"Error processing file {file}: {err}\")\n",
    "                continue\n",
    "                \n",
    "print(f\" Extracted {len(mfcc_features)}files\")\n",
    "for  i in range(10):\n",
    "    print(mfcc_features[i])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850da98",
   "metadata": {},
   "source": [
    "# saving Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2405a6",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "x, y = zip(*mfcc_features)\n",
    "x, y = np.asarray(x), np.asarray(y)\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "save_dir_path = '/home/badri/B/ser/datasets/MFCC_Features'\n",
    "\n",
    "joblib.dump(x, os.path.join(save_dir_path, 'x.joblib'))\n",
    "joblib.dump(y, os.path.join(save_dir_path, 'y.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ca793",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = joblib.load('/home/badri/B/ser/datasets/MFCC_Features/x.joblib')\n",
    "y = joblib.load('/home/badri/B/ser/datasets/MFCC_Features/y.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cbc905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x_train,  x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "x_traincnn = np.expand_dims(x_train, axis = 2)\n",
    "x_testcnn = np.expand_dims(x_test, axis = 2)\n",
    "print(x_traincnn.shape, x_testcnn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb14233",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb6814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(64, 5, padding='same', input_shape=(40, 1)))  # Conv1D layer\n",
    "model.add(Activation('relu'))  # Activation layer\n",
    "model.add(Dropout(0.2))  # Dropout layer\n",
    "model.add(Flatten())  # Flatten layer\n",
    "model.add(Dense(8))  # Dense layer\n",
    "model.add(Activation('softmax'))  # Activation layer\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e34cac",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd1bd4",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model.compile(optimizer=RMSprop(), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_traincnn, y_train, epochs=70, batch_size=32, validation_data=(x_testcnn, y_test))\n",
    "\n",
    "y_pred = model.predict(x_testcnn)\n",
    "y_pred_classes = np.argmax(y_pred, axis =1)\n",
    "print(confusion_matrix(y_test, y_pred_classes))\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b4ff6b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.plot(history.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label = 'loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd8921b",
   "metadata": {},
   "source": [
    "# save model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6aff82",
   "metadata": {},
   "source": [
    "model.save('/home/badri/B/ser/saved_models/model291220241521.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a76ef2",
   "metadata": {},
   "source": [
    "# Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abbaaa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('/home/badri/B/ser/saved_models/model291220241521.keras')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e71eb0",
   "metadata": {},
   "source": [
    "# Methods def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022dd9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_mfcc(file_path, sr = 22050, n_mfcc = 40):\n",
    "    y,sr = librosa.load(file_path, sr=sr, res_type='kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs_mean\n",
    "\n",
    "def audio_input(audio_path):\n",
    "    mfccs = extract_mfcc(audio_path)\n",
    "    new_mfccs = np.expand_dims(mfccs, axis = 0)\n",
    "    new_mfccs = np.expand_dims(new_mfccs, axis = -1)\n",
    "    return new_mfccs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(audio_input('/home/badri/B/ser/datasets/Nappy.wav'))\n",
    "y_pred_class = np.argmax(y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88356a",
   "metadata": {},
   "source": [
    "# Feedback Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda26761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still thinking wheather to use joblib or json -sqlite3 or csv/ txt for storing the feedbacks.\n",
    "\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "DEF_REQ = 50 # Default Request interval for feedbacks is 50 predictions.\n",
    "\n",
    "threashold = DEF_REQ\n",
    "\n",
    "current_score = \"current going prediction from 0.\"\n",
    "\n",
    "def req_feedback(input_data, my_pred):\n",
    "    my_current_score = 0\n",
    "    '''This method requsts feedback about its prediction by  providing the audio to user.'''\n",
    "    display(Audio(input_data, rate = 22050))\n",
    "    print(f\"I predicted it as: {my_pred}\")\n",
    "    is_correct = input(\"Am I correct Y?N: \").strip().lower()\n",
    "    if is_correct == 'y':\n",
    "        threshold *= 2\n",
    "        return False\n",
    "    elif is_correct == 'n':\n",
    "        user_label = input(\"please provide me correct label then..:\").strip().lower()\n",
    "        feedback = input_data, user_label, my_pred\n",
    "        threshold //= 2\n",
    "        return feedback\n",
    "    else:\n",
    "        print(\"Not a valid feedback! Aborting....feedback.\")\n",
    "        \n",
    "    \n",
    "          \n",
    "def is_idle():\n",
    "    '''Need to find  out wheather system is idle or not.'''\n",
    "        \n",
    "def fine_tuning():\n",
    "    if is_idle():\n",
    "        feedbacks = fetch_feedbacks()\n",
    "        optimizer = Adam\n",
    "        if len(feedbacks) == 1:\n",
    "            optimizer.learning_rate = 0.01 # Learnig rate\n",
    "        else:\n",
    "            optimizer.learning_rate = 0.001\n",
    "        model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "        model.fit(x_data, y_data, batch_size = len(feedbacks), epochs = 1, verbose = 0)\n",
    "        # need to handle exceptions\n",
    "        # clear the feedbacks storage for new feedbacks.\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b94b4d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1431f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ser_env)\n",
   "language": "python",
   "name": "ser_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
